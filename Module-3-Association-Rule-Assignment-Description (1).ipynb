{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Module-3-Association-Rule-Assignment-Description.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tdlhXXha-aXb"},"source":["!pip install mlxtend"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDXdglTr-srs","executionInfo":{"status":"ok","timestamp":1615508179265,"user_tz":420,"elapsed":1092,"user":{"displayName":"Ojaswi Dhoubhadel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk3OnSPDc1uQhfMW3FBpomzJ6GO3jVp0HlKO4XmUg=s64","userId":"06018964124818252092"}}},"source":["# libraries you will need for following through this notebook.\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import csv\n","\n","# allow us to view more rows at a time\n","pd.options.display.max_rows = 999\n","pd.options.display.max_colwidth = 999\n","\n","# the functions we need from mlxtend are here\n","from mlxtend.preprocessing import TransactionEncoder\n","from mlxtend.frequent_patterns import apriori, association_rules"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNSbYC5x-0Ii","executionInfo":{"status":"ok","timestamp":1615508180614,"user_tz":420,"elapsed":327,"user":{"displayName":"Ojaswi Dhoubhadel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk3OnSPDc1uQhfMW3FBpomzJ6GO3jVp0HlKO4XmUg=s64","userId":"06018964124818252092"}}},"source":["# The following is code for uploading a file to the colab.research.google \n","# environment.\n","\n","# library for uploading files\n","from google.colab import files \n","\n","def upload_files():\n","    # initiates the upload - follow the dialogues that appear\n","    uploaded = files.upload()\n","\n","    # verify the upload\n","    for fn in uploaded.keys():\n","        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","            name=fn, length=len(uploaded[fn])))\n","\n","    # uploaded files need to be written to file to interact with them\n","    # as part of a file system\n","    for filename in uploaded.keys():\n","        with open(filename, 'wb') as f:\n","            f.write(uploaded[filename])"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w-EWgYUa-4il"},"source":["## Assignment Dataset Description\n","\n","We will be looking at a dataset from an ecommerce company. This dataset has each item purchased on a separate line. The data spans a year of purchases. The fields InvoiceNo and CustomerID can be used to identify the transactions.  Here is more info about the dataset:\n","\n","https://www.kaggle.com/carrie1/ecommerce-data\n","\n","https://archive.ics.uci.edu/ml/datasets/online+retail\n","\n","Please upload the ecommerce-data.csv file we have supplied:"]},{"cell_type":"code","metadata":{"id":"DeFGjHOo-3sZ"},"source":["# upload the ecommerce-data.csv file\n","upload_files()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmp-4Jg2DBay"},"source":["## Parsing the data\n","\n","We have provided a functions for loading the data and for getting the data into transactions. The functions can be found below. Run them so you can call them in the future.\n","\n","The `load_data` function only needs to be called once if you save the output to a variable.\n","\n","The `load_transactions` function allows you to filter by time and to change out transactions are aggregated. You can try changing the parameters and see what kind of output you get.\n","\n","Refer to the comments under each function header for more information.\n","\n","You should load the data and prepare the transactions now."]},{"cell_type":"code","metadata":{"id":"QdS9OeAbMTCF","executionInfo":{"status":"ok","timestamp":1615508202053,"user_tz":420,"elapsed":356,"user":{"displayName":"Ojaswi Dhoubhadel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk3OnSPDc1uQhfMW3FBpomzJ6GO3jVp0HlKO4XmUg=s64","userId":"06018964124818252092"}}},"source":["def load_data():\n","    \"\"\"\n","    Loads the ecommerce dataset as a pandas DataFrame\n","    Returns the DataFrame\n","    \"\"\"\n","    ecom_df = pd.read_csv(\"ecommerce-data.csv\", encoding=\"latin1\")\n","    ecom_df[\"InvoiceDate\"] = pd.to_datetime(ecom_df[\"InvoiceDate\"])\n","    return ecom_df"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSgpV4MiFI0i","executionInfo":{"status":"ok","timestamp":1615508212769,"user_tz":420,"elapsed":254,"user":{"displayName":"Ojaswi Dhoubhadel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjk3OnSPDc1uQhfMW3FBpomzJ6GO3jVp0HlKO4XmUg=s64","userId":"06018964124818252092"}}},"source":["\n","def load_transactions(ecom_df, start_date=None, end_date=None, by_customer=False):\n","    \"\"\"\n","    Turns the DataFrame of the ecommerce data into a list of lists representing transactions\n","    Params:\n","        ecom_df - the DataFrame returned by load_data()\n","        start_date - A start date to filter by, if None then does not filter by start date\n","                     Argument should be a string, format should be \"YYYY-MM-DD\"\n","        end_date - An end date to filter by, if None then does not filter by end date\n","                   Argument should be a string, format should be \"YYYY-MM-DD\"\n","        by_customer - if True, transactions represent all items bought by a customer\n","                      if False, transactions represent each checkout\n","    \n","    Returns the list of lists representing transactions\n","    \"\"\"\n","    if start_date and end_date:\n","        ecom_df_filtered = ecom_df.loc[(ecom_df[\"InvoiceDate\"] >= start_date) & (ecom_df[\"InvoiceDate\"] < end_date), :]\n","    elif start_date:\n","        ecom_df_filtered = ecom_df.loc[(ecom_df[\"InvoiceDate\"] >= start_date), :]\n","    elif end_date:\n","        ecom_df_filtered = ecom_df.loc[(ecom_df[\"InvoiceDate\"] < end_date), :]\n","    else:\n","        ecom_df_filtered = ecom_df\n","    \n","    group_cols = \"CustomerID\" if by_customer else [\"CustomerID\", \"InvoiceNo\"]\n","    \n","    transactions = []\n","    ecom_df_filtered.groupby(group_cols).apply(lambda x, transactions=transactions: transactions.append(x[\"Description\"].tolist()))\n","    return transactions\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KT-f84Y9INNY"},"source":["# Load data here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O6fsLzIeZZ4U"},"source":["## Task\n","\n","Use the functions we discussed in the example notebook to do an Association Rule analysis of the ecommerce data. The basic analysis will have you use the complete dataset to generate some rules and draw some conclusions. There are three steps to the analysis:\n","\n","1) Encode the transactions as a one-hot DataFrame. Use the TransactionEncoder() like shown in the Example notebook.\n","\n","2) Generate the candidate item sets using the apriori function. The tricky part here is choosing a min_support that yields useful item sets, but doesn't take forever to run.\n","\n","3) Generate the associaton rules using the associaton_rules function. The function takes the candidate item set generated by the apriori function. Choose a confidence level that includes some interesting rules. When you display rules, rules should be ordered by Lift.\n","\n"]},{"cell_type":"code","metadata":{"id":"Ai971-XMZ8rJ"},"source":["# begin analysis"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DNaXojdiaN1"},"source":["##Discussion\n","\n","We have some general questions about the rules you found that you can answer:\n","\n","1) What rules did you find that you think are obvious?\n","\n","2) What rules did you find that you think are surprising?\n","\n","3) What rules could yield actions for the e-commerce company? What could these actions be?\n","\n","4) What additional investigations would you do using this data or another data source that could aid in the interpretation of the rules?\n"]},{"cell_type":"markdown","metadata":{"id":"AFbL03aLifSR"},"source":["##Optional Tasks\n","\n","There are some more analysis you can do if time permits:\n","\n","1) Investigate how the time range affects the rules generated. Choosing different time ranges should expose different patterns. What rules exist only at Christmas? What rules are found in the summer?\n","\n","2) Investigate how forming transactions by customer vs by checkout event can affect the rules found. What rules are unique to each method of aggregating transactions? What can this tell you about your customer base?"]}]}